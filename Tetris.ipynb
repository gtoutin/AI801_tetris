{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Dependencies:\n",
    "#!pip install gym_tetris\n",
    "#!pip install nes-py\n",
    "#!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports from external libraries:\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_tetris\n",
    "from gym_tetris.actions import MOVEMENT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "#Necessary imports from other files:\n",
    "#from A_star import TetrisGameState\n",
    "#from A_star import TetrisNode\n",
    "from A_star import AStarTetrisSolver\n",
    "from UCT import UCTTetrisSolver\n",
    "from UCT import CollisionDetection\n",
    "import tetronimoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AStar Check\n",
    "#astartetris = TetrisGameState(\"insert board here\")\n",
    "#node = TetrisNode(\"insert state here\", \"insert position here\", \"insert rotation here\")\n",
    "#solver = AStarTetrisSolver(\"insert start game state here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCT Check\n",
    "#uct = UCTTetrisSolver(\"insert board here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From here on out, this is the actual code of the Tetris program.\n",
    "#It has been split into different blocks, as putting it all in a single block would cause severe lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary constant\n",
    "#This implementation uses the NTSC version of tetris, which has slightly different frames for the falling pieces than the PAL version.\n",
    "#Source for fall frames: https://listfist.com/list-of-tetris-levels-by-speed-nes-ntsc-vs-pal\n",
    "\n",
    "#This is what corresponds to the piece location/rotation, which is found via self.env.ram[0x0042].\n",
    "#It's not particularly useful for our purposes because info[\"current_piece\"] is just outright better, but it is still noteworthy.\n",
    "PieceOrientation = {\n",
    "    \"T\" : [0, 1, 2, 3],\n",
    "    \"J\" : [4, 5, 6, 7],\n",
    "    \"Z\" : [8, 9],\n",
    "    \"O\" : [10],\n",
    "    \"S\" : [11, 12],\n",
    "    \"L\" : [13, 14, 15, 16],\n",
    "    \"I\" : [17, 18]\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NOOP'], ['A'], ['B'], ['right'], ['right', 'A'], ['right', 'B'], ['left'], ['left', 'A'], ['left', 'B'], ['down'], ['down', 'A'], ['down', 'B']]\n"
     ]
    }
   ],
   "source": [
    "print(MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AStarTestBoard = ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
    "#Also starting point of all pieces\n",
    "AStarStartLocation = (5,0)\n",
    "AStarStartPiece = \"Ld\"\n",
    "AStarGoalLocation = (3,17)\n",
    "AStarGoalPiece = \"Ld\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCTTestBoard =   ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (1, 1, 1, 1, 0, 0, 1, 1, 1, 1), \n",
    "                  (1, 1, 1, 1, 0, 1, 1, 1, 1, 1), \n",
    "                  (1, 1, 1, 1, 0, 1, 1, 1, 1, 1))\n",
    "UCTPiece = \"Jl\"\n",
    "UCTNextPiece = \"Iv\"\n",
    "UCTGoalLocation = (4,18) #Jr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the board ripped out from the NES RAM and converts it to a simpler board to use\n",
    "#Is mostly necessary because the board in the NES RAM also takes into account the colors of the pieces, which is not necessary for the algorithm to know.\n",
    "def ColorBoardtoSimpleBoard(board):\n",
    "    simpleboard = []\n",
    "    for row in board:\n",
    "        simplerow = []\n",
    "        for cell in row:\n",
    "            if cell == 239:\n",
    "                simplerow.append(0)\n",
    "            else:\n",
    "                simplerow.append(1)\n",
    "        simpleboard.append(tuple(simplerow))\n",
    "    return tuple(simpleboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use this class, simply run the following line in Agent's action function:\n",
    "#MicroState(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), self.info, tuple(self.env.ram[0x0040:0x0042]), self.env.ram[0x0044], \"NOOP\")\n",
    "#A* Algorithm can then be run via running takeAction function \n",
    "class MicroState:\n",
    "    movement = [['NOOP'], ['A'], ['B'], ['right'], ['right', 'A'], ['right', 'B'], ['left'], ['left', 'A'], ['left', 'B'], ['down'], ['down', 'A'], ['down', 'B']]\n",
    "    SpeedtoFallFrames = [48, 43, 38, 28, 23, 18, 13, 8, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n",
    "    rot2num = {\"v\": 0, \"h\": 1, \"u\": 0, \"r\": 1, \"d\": 2, \"l\": 3}\n",
    "    \n",
    "    def __init__(self, boardstate, currentpiece, piecelocation, goalstate=None, speed=0, previousaction=\"NOOP\", parent=None, g=0):\n",
    "        self.boardstate = boardstate\n",
    "        self.currentpiece = currentpiece\n",
    "        self.piecelocation = list(piecelocation)\n",
    "        self.goalstate = goalstate\n",
    "        self.speed = speed\n",
    "        self.fallframes = self.SpeedtoFallFrames[min(speed, 29)] - 1\n",
    "        self.softdrop = 0\n",
    "        self.previousaction = previousaction\n",
    "        self.parent = parent\n",
    "        self.g_score = g\n",
    "        self.h_score = self.heuristic(goalstate)\n",
    "        self.f_score = self.g_score + self.h_score\n",
    "    \n",
    "    def takeAction(self, action):\n",
    "        bs = copy.deepcopy(self.boardstate)\n",
    "        cp = copy.deepcopy(self.currentpiece)\n",
    "        #pl = copy.deepcopy(self.piecelocation)\n",
    "        \n",
    "        ff = copy.deepcopy(self.fallframes)\n",
    "        sd = copy.deepcopy(self.softdrop)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"A\" in action and \"A\" not in self.previousaction:\n",
    "            if cp[0] != \"O\":\n",
    "                if cp[1] == \"h\":\n",
    "                    cp = cp[0] + \"v\"\n",
    "                elif cp[1] == \"v\":\n",
    "                    cp = cp[0] + \"h\"\n",
    "                elif cp[1] == \"u\":\n",
    "                    cp = cp[0] + \"r\"\n",
    "                elif cp[1] == \"r\":\n",
    "                    cp = cp[0] + \"d\"\n",
    "                elif cp[1] == \"d\":\n",
    "                    cp = cp[0] + \"l\"\n",
    "                elif cp[1] == \"l\":\n",
    "                    cp = cp[0] + \"u\"\n",
    "        \n",
    "        if \"B\" in action and \"B\" not in self.previousaction:\n",
    "            if cp[0] != \"O\":\n",
    "                if cp[1] == \"h\":\n",
    "                    cp = cp[0] + \"v\"\n",
    "                elif cp[1] == \"v\":\n",
    "                    cp = cp[0] + \"h\"\n",
    "                elif cp[1] == \"u\":\n",
    "                    cp = cp[0] + \"l\"\n",
    "                elif cp[1] == \"l\":\n",
    "                    cp = cp[0] + \"d\"\n",
    "                elif cp[1] == \"d\":\n",
    "                    cp = cp[0] + \"r\"\n",
    "                elif cp[1] == \"r\":\n",
    "                    cp = cp[0] + \"u\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        pl = [tetronimoes.TETRO_TRANS[cp][0] + self.piecelocation[0], tetronimoes.TETRO_TRANS[cp][1] + self.piecelocation[1]]\n",
    "        \n",
    "        if \"down\" in action:\n",
    "            if sd == 2 and ff > 1:\n",
    "                pl[1] += 1\n",
    "                sd = 1\n",
    "            elif sd == 0 or sd == 1:\n",
    "                sd += 1\n",
    "        else:\n",
    "            sd = 0\n",
    "            \n",
    "        \n",
    "        if \"left\" in action and \"left\" not in self.previousaction:\n",
    "            pl[0] -= 1\n",
    "            if not CollisionDetection(bs, self.currentpiece, pl):\n",
    "                pl[0] += 1\n",
    "        if \"right\" in action and \"right\" not in self.previousaction:\n",
    "            pl[0] += 1\n",
    "            if not CollisionDetection(bs, self.currentpiece, pl):\n",
    "                pl[0] -= 1\n",
    "        \n",
    "        pl = (pl[0] - tetronimoes.TETRO_TRANS[cp][0], pl[1] - tetronimoes.TETRO_TRANS[cp][1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        ff -= 1\n",
    "        if ff <= 0:\n",
    "            pl[1] += 1\n",
    "        #print(bs, cp, pl, self.goalstate, self.speed, action, copy.deepcopy(self), self.g_score + 1)\n",
    "        \n",
    "        m = MicroState(bs, cp, pl, copy.deepcopy(self.goalstate), copy.deepcopy(self.speed), action, copy.deepcopy(self), copy.deepcopy(self.g_score) + 1)\n",
    "        #print(m)\n",
    "        #print(self)\n",
    "        m.fallframes = ff\n",
    "        m.softdrop = sd\n",
    "        return m\n",
    "    \n",
    "    def heuristic(self, goal):\n",
    "        if goal is None:\n",
    "            return 0\n",
    "        if len(self.currentpiece) == 1:\n",
    "            currot = 0\n",
    "        else:\n",
    "            currot = self.rot2num[self.currentpiece[1]]\n",
    "        \n",
    "        if len(goal.currentpiece) == 1:\n",
    "            goalrot = 0\n",
    "        else:\n",
    "            goalrot = self.rot2num[goal.currentpiece[1]]\n",
    "        rotcost = min(abs(currot - goalrot), abs(((currot + 1) % 4) - ((goalrot + 1) % 4)))\n",
    "        movcostx = 2 * abs(self.piecelocation[0] - goal.piecelocation[0])\n",
    "        \n",
    "        #Since you can't move left/right twice consecutively, this rule has to be added to properly convey the rules\n",
    "        if not ((self.piecelocation[0] - goal.piecelocation[0] < 0 and \"left\" in self.previousaction) or (self.piecelocation[0] - goal.piecelocation[0] > 0 and \"right\" in self.previousaction)):\n",
    "            movcostx = max(0, movcostx - 1)\n",
    "            \n",
    "        movcosty = (2 * abs(self.piecelocation[1] - goal.piecelocation[1])) \n",
    "        if movcosty > 0:\n",
    "            movcosty -= (self.softdrop - 1)\n",
    "        movcost = movcostx + movcosty\n",
    "        if goal.piecelocation[1] < self.piecelocation[1]:\n",
    "            #If goal is above the current piece, it's impossible to reach and should therefore not be added\n",
    "            movcost = 9999\n",
    "        return rotcost + movcost\n",
    "    \n",
    "    def is_goal(self, goal):\n",
    "        return (self.currentpiece == goal.currentpiece and self.piecelocation == goal.piecelocation)\n",
    "    \n",
    "    def generate_neighbors(self):\n",
    "        return tuple([self.takeAction(action) for action in self.movement])\n",
    "    \n",
    "    def __eq__(self,other):\n",
    "        #print(other)\n",
    "        try:\n",
    "            if self.currentpiece == other.currentpiece and tuple(self.piecelocation) == tuple(other.piecelocation) and tuple(self.previousaction) == tuple(other.previousaction) and self.softdrop == other.softdrop:\n",
    "                return True\n",
    "            return False\n",
    "        except:\n",
    "            if self.currentpiece == other[0] and tuple(self.piecelocation) == tuple(other[1]) and tuple(self.previousaction) == tuple(other[2]) and self.softdrop == other[3]:\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    def __lt__(self,other):\n",
    "        if self.f_score < other.f_score:\n",
    "            return True\n",
    "        if self.f_score == other.f_score:\n",
    "            if self.h_score < other.h_score:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def __gt__(self,other):\n",
    "        if self.f_score > other.f_score:\n",
    "            return True\n",
    "        if self.f_score == other.f_score:\n",
    "            if self.h_score > other.h_score:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str([self.currentpiece, self.piecelocation, self.previousaction, self.f_score, self.h_score])\n",
    "    \n",
    "    def __hash__(self):\n",
    "        #print(self.currentpiece)\n",
    "        #print(self.piecelocation)\n",
    "        #print(self.previousaction)\n",
    "        return hash((self.currentpiece, tuple(self.piecelocation), tuple(self.previousaction), self.softdrop))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ld', [5, 0], ['NOOP'], 39, 38]\n",
      "['Ll', [5, 0], ['A'], 40, 39]\n",
      "['Lr', [5, 0], ['B'], 40, 39]\n",
      "['Ld', [6, 0], ['right'], 42, 41]\n",
      "['Ll', [5, 0], ['right', 'A'], 41, 40]\n",
      "['Lr', [5, 0], ['right', 'B'], 41, 40]\n",
      "['Ld', [4, 0], ['left'], 37, 36]\n",
      "['Ll', [5, 0], ['left', 'A'], 40, 39]\n",
      "['Lr', [5, 0], ['left', 'B'], 40, 39]\n",
      "['Ld', [5, 0], ['down'], 39, 38]\n",
      "['Ll', [5, 0], ['down', 'A'], 40, 39]\n",
      "['Lr', [5, 0], ['down', 'B'], 40, 39]\n"
     ]
    }
   ],
   "source": [
    "AGoalState = MicroState(AStarTestBoard, AStarGoalPiece, AStarGoalLocation)\n",
    "AStartState = MicroState(AStarTestBoard, AStarStartPiece, AStarStartLocation, AGoalState)\n",
    "neighbors = AStartState.generate_neighbors()\n",
    "for state in neighbors:\n",
    "    print(state)\n",
    "#print(solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ld', [5, 0], ['NOOP'], 39, 38]\n",
      "['Ll', [5, 0], ['A'], 40, 39]\n",
      "['Lr', [5, 0], ['B'], 40, 39]\n",
      "['Ld', [6, 0], ['right'], 42, 41]\n",
      "['Ll', [5, 0], ['right', 'A'], 41, 40]\n",
      "['Lr', [5, 0], ['right', 'B'], 41, 40]\n",
      "['Ld', [4, 0], ['left'], 37, 36]\n",
      "['Ll', [5, 0], ['left', 'A'], 40, 39]\n",
      "['Lr', [5, 0], ['left', 'B'], 40, 39]\n",
      "['Ld', [5, 0], ['down'], 39, 38]\n",
      "['Ll', [5, 0], ['down', 'A'], 40, 39]\n",
      "['Lr', [5, 0], ['down', 'B'], 40, 39]\n"
     ]
    }
   ],
   "source": [
    "TestJd = MicroState(AStarTestBoard, \"Jd\", (5,0), AGoalState)\n",
    "neighbors = AStartState.generate_neighbors()\n",
    "for state in neighbors:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AStar = AStarTetrisSolver(AStartState, AGoalState)\n",
    "solved = AStar.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['left'], [5, 0])\n",
      "(['down'], [4, 0])\n",
      "(['down'], [4, 0])\n",
      "(['down'], [4, 0])\n",
      "(['down'], [4, 1])\n",
      "(['down'], [4, 1])\n",
      "(['down'], [4, 2])\n",
      "(['down'], [4, 2])\n",
      "(['down'], [4, 3])\n",
      "(['down'], [4, 3])\n",
      "(['down'], [4, 4])\n",
      "(['down'], [4, 4])\n",
      "(['down'], [4, 5])\n",
      "(['down'], [4, 5])\n",
      "(['down'], [4, 6])\n",
      "(['down'], [4, 6])\n",
      "(['down'], [4, 7])\n",
      "(['down'], [4, 7])\n",
      "(['down'], [4, 8])\n",
      "(['down'], [4, 8])\n",
      "(['down'], [4, 9])\n",
      "(['down'], [4, 9])\n",
      "(['down'], [4, 10])\n",
      "(['down'], [4, 10])\n",
      "(['down'], [4, 11])\n",
      "(['down'], [4, 11])\n",
      "(['down'], [4, 12])\n",
      "(['down'], [4, 12])\n",
      "(['down'], [4, 13])\n",
      "(['down'], [4, 13])\n",
      "(['down'], [4, 14])\n",
      "(['down'], [4, 14])\n",
      "(['down'], [4, 15])\n",
      "(['down'], [4, 15])\n",
      "(['down'], [4, 16])\n",
      "(['down'], [4, 16])\n",
      "(['left'], [4, 17])\n",
      "(['down'], [3, 17])\n",
      "(['down'], [3, 17])\n",
      "(['down'], [3, 17])\n",
      "(['NOOP'], [3, 17])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(solved[0])):\n",
    "    print((solved[0][i], solved[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(solved[0]))\n",
    "print(len(solved[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewNode = AStartState.takeAction(\"left\")\n",
    "#print(AStartState.h_score)\n",
    "#print(AStartState)\n",
    "#print(NewNode.parent)\n",
    "#print(NewNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solved.append(['down'])\n",
    "#solved.append(['NOOP'])\n",
    "#solved.append(['NOOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal results:\n",
    "#[(['left', 'A'], [5, 0]), \n",
    "#(['down'], [4, 0]), \n",
    "#(['left'], [4, 0]), \n",
    "#(['down'], [3, 0]), \n",
    "#(['left'], [3, 0]), \n",
    "#(['down'], [2, 0]), \n",
    "#(['down'], [2, 0]), \n",
    "#(['down'], [2, 0]), \n",
    "#(['down'], [2, 1]), \n",
    "#(['down'], [2, 1]), \n",
    "#(['down'], [2, 2]), \n",
    "#(['down'], [2, 2]), \n",
    "#(['down'], [2, 3]), \n",
    "#(['down'], [2, 3]), \n",
    "#(['down'], [2, 4]), \n",
    "#(['down'], [2, 4]), \n",
    "#(['down'], [2, 5]), \n",
    "#(['down'], [2, 5]), \n",
    "#(['down'], [2, 6]), \n",
    "#(['down'], [2, 6]), \n",
    "#(['down'], [2, 7]), \n",
    "#(['down'], [2, 7]), \n",
    "#(['down'], [2, 8]), \n",
    "#(['down'], [2, 8]), \n",
    "#(['down'], [2, 9]), \n",
    "#(['down'], [2, 9]), \n",
    "#(['down'], [2, 10]), \n",
    "#(['down'], [2, 10]), \n",
    "#(['down'], [2, 11]), \n",
    "#(['down'], [2, 11]), \n",
    "#(['down'], [2, 12]), \n",
    "#(['down'], [2, 12]), \n",
    "#(['down'], [2, 13]), \n",
    "#(['down'], [2, 13]), \n",
    "#(['down'], [2, 14]), \n",
    "#(['down'], [2, 14]), \n",
    "#(['down'], [2, 15]), \n",
    "#(['down'], [2, 15]), \n",
    "#(['down'], [2, 16]), \n",
    "#(['down'], [2, 16]), \n",
    "#(['down'], [2, 17]), \n",
    "#(['down'], [2, 17]), \n",
    "#(['left'], [2, 18])]\n",
    "\n",
    "#Actual results:\n",
    "#(['left', 'A'], [5, 0])\n",
    "#(['down'], [5, 0])\n",
    "#(['left'], [4, 0])\n",
    "#(['down'], [4, 0])\n",
    "#(['left'], [3, 0])\n",
    "#(['down'], [3, 0])\n",
    "#(['down'], [2, 0])\n",
    "#(['down'], [2, 0])\n",
    "#(['down'], [2, 0])\n",
    "#(['down'], [2, 1])\n",
    "#(['down'], [2, 1])\n",
    "#(['down'], [2, 2])\n",
    "#(['down'], [2, 2])\n",
    "#(['down'], [2, 3])\n",
    "#(['down'], [2, 3])\n",
    "#(['down'], [2, 4])\n",
    "#(['down'], [2, 4])\n",
    "#(['down'], [2, 5])\n",
    "#(['down'], [2, 5])\n",
    "#(['down'], [2, 6])\n",
    "#(['down'], [2, 6])\n",
    "#(['down'], [2, 7])\n",
    "#(['down'], [2, 7])\n",
    "#(['down'], [2, 8])\n",
    "#(['down'], [2, 8])\n",
    "#(['down'], [2, 9])\n",
    "#(['down'], [2, 9])\n",
    "#(['down'], [2, 10])\n",
    "#(['down'], [2, 10])\n",
    "#(['down'], [2, 11])\n",
    "#(['down'], [2, 11])\n",
    "#(['down'], [2, 12])\n",
    "#(['down'], [2, 12])\n",
    "#(['down'], [2, 13])\n",
    "#(['down'], [2, 13])\n",
    "#(['down'], [2, 14])\n",
    "#(['down'], [2, 14])\n",
    "#(['down'], [2, 15])\n",
    "#(['down'], [2, 15])\n",
    "#(['down'], [2, 16])\n",
    "#(['down'], [2, 16])\n",
    "#(['down'], [2, 17])\n",
    "#(['left'], [2, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use this class, simply run the following line in Agent's action function:\n",
    "##MacroState(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), self.info, self.nextinfo)\n",
    "class MacroState:\n",
    "    \n",
    "    def __init__(self, boardstate, currentpiece, nextpiece):\n",
    "        self.boardstate = boardstate\n",
    "        self.currentpiece = currentpiece\n",
    "        self.next_piece = nextpiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCTTest = MacroState(UCTTestBoard, UCTPiece, UCTNextPiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uct = UCTTetrisSolver(UCTTestBoard, UCTTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(UCTPiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(uct.run(UCTPiece, UCTTestBoard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickg\\anaconda4\\envs\\Env39Copy\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment TetrisA-v2 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\nickg\\anaconda4\\envs\\Env39Copy\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\nickg\\anaconda4\\envs\\Env39Copy\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), (0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
      "(5, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickg\\anaconda4\\envs\\Env39Copy\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "C:\\Users\\nickg\\anaconda4\\envs\\Env39Copy\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'piece': 'Jr', 'location': (7, 18), 'score': -0.8}, {'piece': 'Jd', 'location': (2, 18), 'score': -4.9}, {'piece': 'Ju', 'location': (2, 19), 'score': -6.0}, {'piece': 'Ju', 'location': (1, 19), 'score': -7.6}, {'piece': 'Jd', 'location': (-1, -1), 'score': -1000}]\n",
      "Jd (5, 0)\n",
      "Jr (7, 18)\n",
      "[['right'], ['down', 'B'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['right'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "['Jd', 'Jd', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr', 'Jr']\n",
      "[['right'], ['down', 'B'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['right'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "[{'piece': 'Zv', 'location': (4, 18), 'score': -4.3}, {'piece': 'Zv', 'location': (0, 18), 'score': -6.3}, {'piece': 'Zh', 'location': (5, 18), 'score': -6.9}, {'piece': 'Zh', 'location': (2, 18), 'score': -7.5}, {'piece': 'Zh', 'location': (1, 18), 'score': -9.2}, {'piece': 'Zh', 'location': (-1, -1), 'score': -1000}]\n",
      "Zh (5, 0)\n",
      "Zv (4, 18)\n",
      "[['down', 'A'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "['Zh', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv', 'Zv']\n",
      "[['down', 'A'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "[{'piece': 'O', 'location': (1, 18), 'score': -7.1}, {'piece': 'O', 'location': (-1, -1), 'score': -1000}]\n",
      "O (5, 0)\n",
      "O (1, 18)\n",
      "[['left', 'A'], ['down'], ['left'], ['down'], ['left', 'A'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down', 'A'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['left', 'A'], ['down'], ['left'], ['down'], ['left', 'A'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down', 'A'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "[{'piece': 'Sv', 'location': (0, 16), 'score': -7.7}, {'piece': 'Sh', 'location': (4, 16), 'score': -8.0}, {'piece': 'Sh', 'location': (2, 16), 'score': -8.4}, {'piece': 'Sh', 'location': (1, 16), 'score': -9.7}, {'piece': 'Sh', 'location': (-1, -1), 'score': -1000}]\n",
      "Sh (5, 0)\n",
      "Sv (0, 16)\n",
      "[['down', 'B'], ['down'], ['down'], ['left'], ['down'], ['left'], ['down'], ['left'], ['down'], ['left'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "['Sh', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv', 'Sv']\n",
      "[['down', 'B'], ['down'], ['down'], ['left'], ['down'], ['left'], ['down'], ['left'], ['down'], ['left'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "[{'piece': 'Ld', 'location': (3, 17), 'score': 7.1}, {'piece': 'Lu', 'location': (2, 15), 'score': -5.5}, {'piece': 'Lu', 'location': (1, 14), 'score': -7.9}, {'piece': 'Ld', 'location': (-1, -1), 'score': -1000}]\n",
      "Ld (5, 0)\n",
      "Ld (3, 17)\n",
      "[['left', 'B'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "['Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld']\n",
      "Error: AStar search does not match actual rotation\n",
      "Ld\n",
      "Lr\n",
      "1\n",
      "[['left', 'B'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['down'], ['left'], ['down'], ['down'], ['down'], ['NOOP']]\n",
      "['Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld', 'Ld']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 245\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# comparison\u001b[39;00m\n\u001b[0;32m    244\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(episodes\u001b[38;5;241m=\u001b[39mN_EPISODES, num_sims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_pieces \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 245\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m highscores \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mlistofhighscores\n\u001b[0;32m    248\u001b[0m highscorerates \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mlistofhighscorerates\n",
      "Cell \u001b[1;32mIn[30], line 165\u001b[0m, in \u001b[0;36mAgent.play\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactiontape)\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcptape)\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m#if tuple(self.loctape[iterator]) != tuple(self.env.ram[0x0040:0x0042]):\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m#    raise ValueError\u001b[39;00m\n\u001b[0;32m    170\u001b[0m action \u001b[38;5;241m=\u001b[39m MOVEMENT\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactiontape[iterator])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Agent class itself\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, episodes=1, num_sims=10, num_pieces=2):\n",
    "        self.env = gym_tetris.make('TetrisA-v2',deterministic = True)\n",
    "        self.env = JoypadSpace(self.env, MOVEMENT)\n",
    "        self.env.deterministic = True\n",
    "        #Testing to see whether using the pixels for the state works better than just the board.\n",
    "        #self.state = self.env.reset()\n",
    "        self.env.reset()\n",
    "        self.env.deterministic = True\n",
    "        self.env.render()\n",
    "        self.state = tuple([ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), \"\", \"\", tuple(self.env.ram[0x0040:0x0042])])\n",
    "        print(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()))\n",
    "        print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "        #print(self.env.ram[0x0044])\n",
    "        self.info = \"NONE\"\n",
    "        self.nextinfo = \"NONE\"\n",
    "        self.prevaction = \"NOOP\"\n",
    "        self.highscore = 0\n",
    "        self.time = 0\n",
    "        self.linestates = []\n",
    "        self.listofhighscores = []\n",
    "        self.listofhighscorerates = []\n",
    "        self.listofsafetyscores = []\n",
    "        \n",
    "        \n",
    "        self.actions = MOVEMENT\n",
    "        self.state_actions = []  # state & action track\n",
    "\n",
    "        self.episodes = episodes  # number of episodes going to play\n",
    "        self.steps_per_episode = []\n",
    "        \n",
    "        self.num_sims = num_sims\n",
    "        self.num_pieces = num_pieces\n",
    "        \n",
    "        self.actiontape = []\n",
    "        self.loctape = []\n",
    "        self.cptape = []\n",
    "        \n",
    "        \n",
    "    def chooseAction(self):\n",
    "        #action = 0\n",
    "        \n",
    "        #print(self.actions)\n",
    "        if self.info == \"NONE\":\n",
    "            action = np.random.choice(len(self.actions))\n",
    "        else:\n",
    "            #Algorithms go here\n",
    "            Board = ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy())\n",
    "            #for row in Board:\n",
    "            #    print(row)\n",
    "            \n",
    "            UCTTest = MacroState(Board, self.info, self.nextinfo)\n",
    "            UCT = UCTTetrisSolver(Board, UCTTest)\n",
    "            UCTResult = UCT.run(self.info, Board, self.num_sims, self.num_pieces)\n",
    "            \n",
    "            AStarGoalPiece = UCTResult[0]['piece']\n",
    "            self.goallocation = UCTResult[0]['location']\n",
    "            AStarGoalLocation = UCTResult[0]['location']\n",
    "            AGoalState = MicroState(Board, AStarGoalPiece, AStarGoalLocation)\n",
    "            AStartState = MicroState(Board, self.info, tuple(self.env.ram[0x0040:0x0042]), AGoalState, self.env.ram[0x0044], self.prevaction)\n",
    "            #print(self.env.ram[0x0044])\n",
    "            \n",
    "            \n",
    "            AStar = AStarTetrisSolver(AStartState, AGoalState)\n",
    "            AStarResult = AStar.solve()\n",
    "            print(UCTResult)\n",
    "            print(self.info, tuple(self.env.ram[0x0040:0x0042]))\n",
    "            print(AStarGoalPiece, AStarGoalLocation)\n",
    "            \n",
    "            #print(AStarResult)\n",
    "            if AStarResult is None:\n",
    "                #self.env.close()\n",
    "                #print(AStarGoalPiece, AStarGoalLocation)\n",
    "                raise IndexError\n",
    "            \n",
    "            self.actiontape = AStarResult[0]\n",
    "            self.loctape = AStarResult[1]\n",
    "            self.cptape = AStarResult[2]\n",
    "            action = MOVEMENT.index(self.actiontape[0])\n",
    "            print(self.actiontape)\n",
    "            print(self.cptape)\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.prevaction = MOVEMENT[action]\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.close()\n",
    "        self.env = gym_tetris.make('TetrisA-v2',deterministic = True)\n",
    "        self.env = JoypadSpace(self.env, MOVEMENT)\n",
    "        self.env.deterministic = True\n",
    "        self.env.reset()\n",
    "        self.env.deterministic = True\n",
    "        self.env.render()\n",
    "        self.state = tuple([ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), \"\", \"\", tuple(self.env.ram[0x0040:0x0042])])\n",
    "        self.info = \"NONE\"\n",
    "        self.nextinfo = \"NONE\"\n",
    "        self.prevaction = \"NOOP\"\n",
    "        #Conversion of self.state to tuple for hashing purposes\n",
    "        #self.state = tuple([tuple(x) for x in self.state])\n",
    "        self.state_actions = []\n",
    "        self.highscore = 0\n",
    "        self.time = 0\n",
    "        self.linestates = []\n",
    "        \n",
    "        self.actiontape = []\n",
    "\n",
    "\n",
    "    def play(self):\n",
    "        self.steps_per_episode = []  \n",
    "        \n",
    "        for ep in range(self.episodes):\n",
    "            done = False\n",
    "            once = True\n",
    "            iterator = 1\n",
    "            while not done:\n",
    "                \n",
    "                \n",
    "                if self.env.ram[0x0048] != 1: #Player is not in control\n",
    "                    action = 0 #NOOP\n",
    "                    once = True\n",
    "                    if self.goallocation != tuple(self.env.ram[0x0040:0x0042]) and errorthrow:\n",
    "                        #print(\"Error: AStar search does not match actual results\")\n",
    "                        print(self.goallocation)\n",
    "                        print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "                        errorthrow = False\n",
    "                    \n",
    "                    \n",
    "                    if len(self.actiontape) > 0: #Contingency so that actiontape from one piece does not carry over to the next\n",
    "                        print(self.actiontape)\n",
    "                        self.actiontape = []\n",
    "                elif once: #Necessary to NOOP at first frame of piece because otherwise desync can occur\n",
    "                    once = False\n",
    "                    action = 0 #NOOP\n",
    "                \n",
    "                elif iterator >= len(self.actiontape):\n",
    "                    action = self.chooseAction()\n",
    "                    iterator = 1\n",
    "                    errorthrow = True\n",
    "                else:\n",
    "                    \n",
    "                    \n",
    "                    #print(self.loctape[0])\n",
    "                    #print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "                    if tuple(self.loctape[iterator-1]) != tuple(self.env.ram[0x0040:0x0042]):\n",
    "                        print(\"Error: AStar search does not match actual location\")\n",
    "                        print(self.loctape[iterator-1])\n",
    "                        print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "                        print(iterator-1)\n",
    "                        print(self.actiontape)\n",
    "                        print(self.loctape)\n",
    "                        #raise ValueError\n",
    "                    \n",
    "                    if self.cptape[iterator-1] != self.info:\n",
    "                        print(\"Error: AStar search does not match actual rotation\")\n",
    "                        print(self.cptape[iterator-1])\n",
    "                        print(self.info)\n",
    "                        print(iterator-1)\n",
    "                        print(self.actiontape)\n",
    "                        print(self.cptape)\n",
    "                        raise RuntimeError\n",
    "                    \n",
    "                    #if tuple(self.loctape[iterator]) != tuple(self.env.ram[0x0040:0x0042]):\n",
    "                    #    raise ValueError\n",
    "                    \n",
    "                    action = MOVEMENT.index(self.actiontape[iterator])\n",
    "                    iterator += 1\n",
    "                    #del self.actiontape[0]\n",
    "                    #del self.loctape[0]\n",
    "                    #del self.cptape[0]\n",
    "                    errorthrow = True\n",
    "                #self.oops = False\n",
    "                self.state_actions.append((self.state, action))\n",
    "                try:\n",
    "                    previnfo = info[\"current_piece\"]\n",
    "                except:\n",
    "                    j = \"j\"\n",
    "\n",
    "                #unusedstate, reward, done, info = self.env.step(self.env.action_space.sample())\n",
    "                \n",
    "                #print((MOVEMENT[action], list(self.env.ram[0x0040:0x0042])))\n",
    "                #time.sleep(1)\n",
    "                \n",
    "                unusedstate, reward, done, info = self.env.step(action)\n",
    "                \n",
    "                #print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "                #time.sleep(1)\n",
    "                \n",
    "                #print(self.env.ram[0x0045])\n",
    "                #try:\n",
    "                #    if previnfo[0] != info[\"current_piece\"][0]:\n",
    "                        #print(previnfo)\n",
    "                        #print(prevpos)\n",
    "                        #Time assuming no action: 960\n",
    "                        #Time assuming down: 49\n",
    "                        #print(self.time)\n",
    "                #        self.oops = True\n",
    "                #except:\n",
    "                #    j = \"j\"\n",
    "                #print(info[\"current_piece\"])\n",
    "                #print(info[\"next_piece\"])\n",
    "                #print(self.env.ram[0x0042])\n",
    "                #if self.env.ram[0x0048] != 1:\n",
    "                #    print(self.time)\n",
    "                \n",
    "                self.env.render()\n",
    "                self.state = tuple([ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), info[\"current_piece\"], info[\"next_piece\"], tuple(self.env.ram[0x0040:0x0042])])\n",
    "                self.info = info[\"current_piece\"]\n",
    "                self.nextinfo = info[\"next_piece\"]\n",
    "                \n",
    "                #if info[\"current_piece\"] == \"Tu\":\n",
    "                    #print(info[\"current_piece\"])\n",
    "                    #time.sleep(10)\n",
    "                \n",
    "                #if CollisionDetection(self.state[0], self.state[1], self.state[3]) == False:\n",
    "                    #print(self.state[1])\n",
    "                    #print(self.state[3])\n",
    "                    #time.sleep(10)\n",
    "                \n",
    "                self.highscore = info[\"score\"]\n",
    "                self.time += 1\n",
    "                self.linestates.append(info[\"board_height\"])\n",
    "\n",
    "            # end of game\n",
    "            #if ep % 10 == 0:\n",
    "            self.listofhighscores.append(self.highscore)\n",
    "            self.listofhighscorerates.append(self.highscore / self.time)\n",
    "            self.listofsafetyscores.append(sum(self.linestates) / self.time)\n",
    "            print(\"episode\", ep)\n",
    "            print(\"Highscore: \" + str(self.highscore))\n",
    "            print(\"Score rate: \" + str(self.highscore / self.time))\n",
    "            print(\"Safety score: \" + str(sum(self.linestates) / self.time))\n",
    "            self.steps_per_episode.append(len(self.state_actions))\n",
    "            #print(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()))\n",
    "            self.reset()\n",
    "        self.env.close()\n",
    "if __name__ == \"__main__\":\n",
    "    N_EPISODES = 1\n",
    "    # comparison\n",
    "    agent = Agent(episodes=N_EPISODES, num_sims=10, num_pieces = 2)\n",
    "    agent.play()\n",
    "\n",
    "    highscores = agent.listofhighscores\n",
    "    highscorerates = agent.listofhighscorerates\n",
    "    safetyscores = agent.listofsafetyscores\n",
    "\n",
    "    plt.figure(figsize=[10, 6])\n",
    "    plt.ylim(0, 50)\n",
    "    plt.plot(range(N_EPISODES), highscores, label=\"high score\")\n",
    "    plt.legend()\n",
    "        \n",
    "    plt.figure(figsize=[10, 6])\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.plot(range(N_EPISODES), highscorerates, label=\"score rate\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(figsize=[10, 6])\n",
    "    plt.ylim(4, 12)\n",
    "    plt.plot(range(N_EPISODES), safetyscores, label=\"safety score\")\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
