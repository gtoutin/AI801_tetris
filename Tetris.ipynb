{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Dependencies:\n",
    "#!pip install gym_tetris\n",
    "#!pip install nes-py\n",
    "#!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports from external libraries:\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_tetris\n",
    "from gym_tetris.actions import MOVEMENT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "#Necessary imports from other files:\n",
    "#from A_star import TetrisGameState\n",
    "#from A_star import TetrisNode\n",
    "from A_star import AStarTetrisSolver\n",
    "from UCT import UCTTetrisSolver\n",
    "from CollisionDetection import CollisionDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AStar Check\n",
    "#astartetris = TetrisGameState(\"insert board here\")\n",
    "#node = TetrisNode(\"insert state here\", \"insert position here\", \"insert rotation here\")\n",
    "#solver = AStarTetrisSolver(\"insert start game state here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCT Check\n",
    "#uct = UCTTetrisSolver(\"insert board here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From here on out, this is the actual code of the Tetris program.\n",
    "#It has been split into different blocks, as putting it all in a single block would cause severe lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary constant\n",
    "#This implementation uses the NTSC version of tetris, which has slightly different frames for the falling pieces than the PAL version.\n",
    "#Source for fall frames: https://listfist.com/list-of-tetris-levels-by-speed-nes-ntsc-vs-pal\n",
    "\n",
    "#This is what corresponds to the piece location/rotation, which is found via self.env.ram[0x0042].\n",
    "#It's not particularly useful for our purposes because info[\"current_piece\"] is just outright better, but it is still noteworthy.\n",
    "PieceOrientation = {\n",
    "    \"T\" : [0, 1, 2, 3],\n",
    "    \"J\" : [4, 5, 6, 7],\n",
    "    \"Z\" : [8, 9],\n",
    "    \"O\" : [10],\n",
    "    \"S\" : [11, 12],\n",
    "    \"L\" : [13, 14, 15, 16],\n",
    "    \"I\" : [17, 18]\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AStarTestBoard = ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
    "#Also starting point of all pieces\n",
    "AStarStartLocation = (5,0)\n",
    "AStarStartPiece = \"Jd\"\n",
    "AStarGoalLocation = (1,18)\n",
    "AStarGoalPiece = \"Jl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCTTestBoard =   ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (0, 1, 0, 1, 0, 0, 1, 0, 1, 0), \n",
    "                  (1, 1, 1, 1, 0, 0, 1, 1, 1, 1), \n",
    "                  (1, 1, 1, 1, 0, 1, 1, 1, 1, 1), \n",
    "                  (1, 1, 1, 1, 0, 1, 1, 1, 1, 1))\n",
    "UCTPiece = \"Jl\"\n",
    "UCTNextPiece = \"Iv\"\n",
    "UCTGoalLocation = (4,18) #Jr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the board ripped out from the NES RAM and converts it to a simpler board to use\n",
    "#Is mostly necessary because the board in the NES RAM also takes into account the colors of the pieces, which is not necessary for the algorithm to know.\n",
    "def ColorBoardtoSimpleBoard(board):\n",
    "    simpleboard = []\n",
    "    for row in board:\n",
    "        simplerow = []\n",
    "        for cell in row:\n",
    "            if cell == 239:\n",
    "                simplerow.append(0)\n",
    "            else:\n",
    "                simplerow.append(1)\n",
    "        simpleboard.append(tuple(simplerow))\n",
    "    return tuple(simpleboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use this class, simply run the following line in Agent's action function:\n",
    "#MicroState(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), self.info, tuple(self.env.ram[0x0040:0x0042]), self.env.ram[0x0044], \"NOOP\")\n",
    "#A* Algorithm can then be run via running takeAction function \n",
    "class MicroState:\n",
    "    movement = [['NOOP'], ['A'], ['B'], ['right'], ['right', 'A'], ['right', 'B'], ['left'], ['left', 'A'], ['left', 'B'], ['down'], ['down', 'A'], ['down', 'B']]\n",
    "    SpeedtoFallFrames = [48, 43, 38, 28, 23, 18, 13, 8, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n",
    "    rot2num = {\"v\": 0, \"h\": 1, \"u\": 0, \"r\": 1, \"d\": 2, \"l\": 3}\n",
    "    \n",
    "    def __init__(self, boardstate, currentpiece, piecelocation, goalstate=None, speed=0, previousaction=\"NOOP\", parent=None, g=0):\n",
    "        self.boardstate = boardstate\n",
    "        self.currentpiece = currentpiece\n",
    "        self.piecelocation = list(piecelocation)\n",
    "        self.goalstate = goalstate\n",
    "        self.speed = speed\n",
    "        self.fallframes = self.SpeedtoFallFrames[min(speed, 29)] - 1\n",
    "        self.softdrop = 0\n",
    "        self.previousaction = previousaction\n",
    "        self.parent = parent\n",
    "        self.g_score = g\n",
    "        self.h_score = self.heuristic(goalstate)\n",
    "        self.f_score = self.g_score + self.h_score\n",
    "    \n",
    "    def takeAction(self, action):\n",
    "        bs = copy.deepcopy(self.boardstate)\n",
    "        cp = copy.deepcopy(self.currentpiece)\n",
    "        pl = copy.deepcopy(self.piecelocation)\n",
    "        ff = copy.deepcopy(self.fallframes)\n",
    "        sd = copy.deepcopy(self.softdrop)\n",
    "        if \"down\" in action:\n",
    "            if sd == 2 and ff > 1:\n",
    "                pl[1] += 1\n",
    "                sd = 1\n",
    "            elif sd == 0 or sd == 1:\n",
    "                sd += 1\n",
    "        else:\n",
    "            sd = 0\n",
    "        if \"left\" in action and \"left\" not in self.previousaction:\n",
    "            pl[0] -= 1\n",
    "            if not CollisionDetection(bs, self.currentpiece, pl):\n",
    "                pl[0] += 1\n",
    "        if \"right\" in action and \"right\" not in self.previousaction:\n",
    "            pl[0] += 1\n",
    "            if not CollisionDetection(bs, self.currentpiece, pl):\n",
    "                pl[0] -= 1\n",
    "        if \"A\" in action and \"A\" not in self.previousaction:\n",
    "            if cp[0] != \"O\":\n",
    "                if cp[1] == \"h\":\n",
    "                    cp = cp[0] + \"v\"\n",
    "                elif cp[1] == \"v\":\n",
    "                    cp[1] = \"h\"\n",
    "                elif cp[1] == \"u\":\n",
    "                    cp = cp[0] + \"r\"\n",
    "                elif cp[1] == \"r\":\n",
    "                    cp = cp[0] + \"d\"\n",
    "                elif cp[1] == \"d\":\n",
    "                    cp = cp[0] + \"l\"\n",
    "                elif cp[1] == \"l\":\n",
    "                    cp = cp[0] + \"u\"\n",
    "        \n",
    "        if \"B\" in action and \"B\" not in self.previousaction:\n",
    "            if cp[0] != \"O\":\n",
    "                if cp[1] == \"h\":\n",
    "                    cp = cp[0] + \"v\"\n",
    "                elif cp[1] == \"v\":\n",
    "                    cp = cp[0] + \"h\"\n",
    "                elif cp[1] == \"u\":\n",
    "                    cp = cp[0] + \"l\"\n",
    "                elif cp[1] == \"l\":\n",
    "                    cp = cp[0] + \"d\"\n",
    "                elif cp[1] == \"d\":\n",
    "                    cp = cp[0] + \"r\"\n",
    "                elif cp[1] == \"r\":\n",
    "                    cp = cp[0] + \"u\"\n",
    "        \n",
    "        ff -= 1\n",
    "        if ff <= 0:\n",
    "            pl[1] += 1\n",
    "        #print(bs, cp, pl, self.goalstate, self.speed, action, copy.deepcopy(self), self.g_score + 1)\n",
    "        m = MicroState(bs, cp, pl, copy.deepcopy(self.goalstate), copy.deepcopy(self.speed), action, copy.deepcopy(self), copy.deepcopy(self.g_score) + 1)\n",
    "        #print(m)\n",
    "        #print(self)\n",
    "        m.fallframes = ff\n",
    "        m.softdrop = sd\n",
    "        return m\n",
    "    \n",
    "    def heuristic(self, goal):\n",
    "        if goal is None:\n",
    "            return 0\n",
    "        if len(self.currentpiece) == 1:\n",
    "            currot = 0\n",
    "        else:\n",
    "            currot = self.rot2num[self.currentpiece[-1]]\n",
    "        \n",
    "        if len(goal.currentpiece) == 1:\n",
    "            goalrot = 0\n",
    "        else:\n",
    "            goalrot = self.rot2num[goal.currentpiece[-1]]\n",
    "        rotcost = min(abs(currot - goalrot), abs(((currot + 1) % 4) - ((goalrot + 1) % 4)))\n",
    "        movcostx = 2 * abs(self.piecelocation[0] - goal.piecelocation[0])\n",
    "        \n",
    "        #Since you can't move left/right twice consecutively, this rule has to be added to properly convey the rules\n",
    "        if not ((self.piecelocation[0] - goal.piecelocation[0] < 0 and \"left\" in self.previousaction) or (self.piecelocation[0] - goal.piecelocation[0] > 0 and \"right\" in self.previousaction)):\n",
    "            movcostx = max(0, movcostx - 1)\n",
    "            \n",
    "        movcosty = (2 * abs(self.piecelocation[1] - goal.piecelocation[1])) \n",
    "        if movcosty > 0:\n",
    "            movcosty -= (self.softdrop - 1)\n",
    "        movcost = movcostx + movcosty\n",
    "        if goal.piecelocation[1] < self.piecelocation[1]:\n",
    "            #If goal is above the current piece, it's impossible to reach and should therefore not be added\n",
    "            movcost = 9999\n",
    "        return rotcost + movcost\n",
    "    \n",
    "    def is_goal(self, goal):\n",
    "        return (self.currentpiece == goal.currentpiece and self.piecelocation == goal.piecelocation)\n",
    "    \n",
    "    def generate_neighbors(self):\n",
    "        return tuple([self.takeAction(action) for action in self.movement])\n",
    "    \n",
    "    def __eq__(self,other):\n",
    "        #print(other)\n",
    "        try:\n",
    "            if self.currentpiece == other.currentpiece and tuple(self.piecelocation) == tuple(other.piecelocation) and tuple(self.previousaction) == tuple(other.previousaction) and self.softdrop == other.softdrop:\n",
    "                return True\n",
    "            return False\n",
    "        except:\n",
    "            if self.currentpiece == other[0] and tuple(self.piecelocation) == tuple(other[1]) and tuple(self.previousaction) == tuple(other[2]) and self.softdrop == other[3]:\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    def __lt__(self,other):\n",
    "        if self.f_score < other.f_score:\n",
    "            return True\n",
    "        if self.f_score == other.f_score:\n",
    "            if self.h_score < other.h_score:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def __gt__(self,other):\n",
    "        if self.f_score > other.f_score:\n",
    "            return True\n",
    "        if self.f_score == other.f_score:\n",
    "            if self.h_score > other.h_score:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str([self.currentpiece, self.piecelocation, self.previousaction, self.f_score, self.h_score])\n",
    "    \n",
    "    def __hash__(self):\n",
    "        #print(self.currentpiece)\n",
    "        #print(self.piecelocation)\n",
    "        #print(self.previousaction)\n",
    "        return hash((self.currentpiece, tuple(self.piecelocation), tuple(self.previousaction), self.softdrop))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGoalState = MicroState(AStarTestBoard, AStarGoalPiece, AStarGoalLocation)\n",
    "AStartState = MicroState(AStarTestBoard, AStarStartPiece, AStarStartLocation, AGoalState)\n",
    "AStar = AStarTetrisSolver(AStartState, AGoalState)\n",
    "solved = AStar.solve()\n",
    "#print(solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewNode = AStartState.takeAction(\"left\")\n",
    "#print(AStartState.h_score)\n",
    "#print(AStartState)\n",
    "#print(NewNode.parent)\n",
    "#print(NewNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solved.append(['down'])\n",
    "#solved.append(['NOOP'])\n",
    "#solved.append(['NOOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal results:\n",
    "#[(['left', 'A'], [5, 0]), \n",
    "#(['down'], [4, 0]), \n",
    "#(['left'], [4, 0]), \n",
    "#(['down'], [3, 0]), \n",
    "#(['left'], [3, 0]), \n",
    "#(['down'], [2, 0]), \n",
    "#(['down'], [2, 0]), \n",
    "#(['down'], [2, 0]), \n",
    "#(['down'], [2, 1]), \n",
    "#(['down'], [2, 1]), \n",
    "#(['down'], [2, 2]), \n",
    "#(['down'], [2, 2]), \n",
    "#(['down'], [2, 3]), \n",
    "#(['down'], [2, 3]), \n",
    "#(['down'], [2, 4]), \n",
    "#(['down'], [2, 4]), \n",
    "#(['down'], [2, 5]), \n",
    "#(['down'], [2, 5]), \n",
    "#(['down'], [2, 6]), \n",
    "#(['down'], [2, 6]), \n",
    "#(['down'], [2, 7]), \n",
    "#(['down'], [2, 7]), \n",
    "#(['down'], [2, 8]), \n",
    "#(['down'], [2, 8]), \n",
    "#(['down'], [2, 9]), \n",
    "#(['down'], [2, 9]), \n",
    "#(['down'], [2, 10]), \n",
    "#(['down'], [2, 10]), \n",
    "#(['down'], [2, 11]), \n",
    "#(['down'], [2, 11]), \n",
    "#(['down'], [2, 12]), \n",
    "#(['down'], [2, 12]), \n",
    "#(['down'], [2, 13]), \n",
    "#(['down'], [2, 13]), \n",
    "#(['down'], [2, 14]), \n",
    "#(['down'], [2, 14]), \n",
    "#(['down'], [2, 15]), \n",
    "#(['down'], [2, 15]), \n",
    "#(['down'], [2, 16]), \n",
    "#(['down'], [2, 16]), \n",
    "#(['down'], [2, 17]), \n",
    "#(['down'], [2, 17]), \n",
    "#(['left'], [2, 18])]\n",
    "\n",
    "#Actual results:\n",
    "#(['left', 'A'], [5, 0])\n",
    "#(['down'], [5, 0])\n",
    "#(['left'], [4, 0])\n",
    "#(['down'], [4, 0])\n",
    "#(['left'], [3, 0])\n",
    "#(['down'], [3, 0])\n",
    "#(['down'], [2, 0])\n",
    "#(['down'], [2, 0])\n",
    "#(['down'], [2, 0])\n",
    "#(['down'], [2, 1])\n",
    "#(['down'], [2, 1])\n",
    "#(['down'], [2, 2])\n",
    "#(['down'], [2, 2])\n",
    "#(['down'], [2, 3])\n",
    "#(['down'], [2, 3])\n",
    "#(['down'], [2, 4])\n",
    "#(['down'], [2, 4])\n",
    "#(['down'], [2, 5])\n",
    "#(['down'], [2, 5])\n",
    "#(['down'], [2, 6])\n",
    "#(['down'], [2, 6])\n",
    "#(['down'], [2, 7])\n",
    "#(['down'], [2, 7])\n",
    "#(['down'], [2, 8])\n",
    "#(['down'], [2, 8])\n",
    "#(['down'], [2, 9])\n",
    "#(['down'], [2, 9])\n",
    "#(['down'], [2, 10])\n",
    "#(['down'], [2, 10])\n",
    "#(['down'], [2, 11])\n",
    "#(['down'], [2, 11])\n",
    "#(['down'], [2, 12])\n",
    "#(['down'], [2, 12])\n",
    "#(['down'], [2, 13])\n",
    "#(['down'], [2, 13])\n",
    "#(['down'], [2, 14])\n",
    "#(['down'], [2, 14])\n",
    "#(['down'], [2, 15])\n",
    "#(['down'], [2, 15])\n",
    "#(['down'], [2, 16])\n",
    "#(['down'], [2, 16])\n",
    "#(['down'], [2, 17])\n",
    "#(['left'], [2, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use this class, simply run the following line in Agent's action function:\n",
    "##MacroState(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), self.info, self.nextinfo)\n",
    "class MacroState:\n",
    "    \n",
    "    def __init__(self, boardstate, currentpiece, nextpiece):\n",
    "        self.boardstate = boardstate\n",
    "        self.currentpiece = currentpiece\n",
    "        self.next_piece = nextpiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCTTest = MacroState(UCTTestBoard, UCTPiece, UCTNextPiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uct = UCTTetrisSolver(UCTTestBoard, UCTTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(UCTPiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uct.run(UCTPiece, UCTTestBoard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent class itself\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, test, episodes=1):\n",
    "        self.env = gym_tetris.make('TetrisA-v2',deterministic = True)\n",
    "        self.env = JoypadSpace(self.env, MOVEMENT)\n",
    "        self.env.deterministic = True\n",
    "        #Testing to see whether using the pixels for the state works better than just the board.\n",
    "        #self.state = self.env.reset()\n",
    "        self.env.reset()\n",
    "        self.env.deterministic = True\n",
    "        self.env.render()\n",
    "        self.state = tuple([ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), \"\", \"\", tuple(self.env.ram[0x0040:0x0042])])\n",
    "        print(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()))\n",
    "        print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "        #print(self.env.ram[0x0044])\n",
    "        self.info = \"NONE\"\n",
    "        self.nextinfo = \"NONE\"\n",
    "        self.prevaction = \"NOOP\"\n",
    "        self.highscore = 0\n",
    "        self.time = 0\n",
    "        self.linestates = []\n",
    "        self.listofhighscores = []\n",
    "        self.listofhighscorerates = []\n",
    "        self.listofsafetyscores = []\n",
    "        self.move = copy.deepcopy(test)\n",
    "        \n",
    "        self.actions = MOVEMENT\n",
    "        self.state_actions = []  # state & action track\n",
    "\n",
    "        self.episodes = episodes  # number of episodes going to play\n",
    "        self.steps_per_episode = []\n",
    "        \n",
    "        self.oops = True\n",
    "        \n",
    "    def chooseAction(self):\n",
    "        #action = 0\n",
    "        \n",
    "        #print(self.actions)\n",
    "        if self.info == \"NONE\":\n",
    "            action = np.random.choice(len(self.actions))\n",
    "        else:\n",
    "            #Algorithms go here\n",
    "            j = \"j\"\n",
    "            \n",
    "            MacroState(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), self.info, self.nextinfo)\n",
    "            \n",
    "            MicroState(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), self.info, tuple(self.env.ram[0x0040:0x0042]), None, self.env.ram[0x0044], self.prevaction)\n",
    "            action = np.random.choice(len(self.actions))\n",
    "        #if self.oops:\n",
    "        #    action = 0\n",
    "        #else:\n",
    "        #    action = 9\n",
    "        if self.env.ram[0x0048] != 1:\n",
    "            action = 0\n",
    "        else:\n",
    "            try:\n",
    "                action = MOVEMENT.index(self.move[0])\n",
    "                del self.move[0]\n",
    "            except:\n",
    "                print(self.time)\n",
    "                self.env.close()\n",
    "                raise IndexError\n",
    "        self.prevaction = action\n",
    "        return action\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.close()\n",
    "        self.env = gym_tetris.make('TetrisA-v2',deterministic = True)\n",
    "        self.env = JoypadSpace(self.env, MOVEMENT)\n",
    "        self.env.deterministic = True\n",
    "        self.env.reset()\n",
    "        self.env.deterministic = True\n",
    "        self.env.render()\n",
    "        self.state = tuple([ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), \"\", \"\", tuple(self.env.ram[0x0040:0x0042])])\n",
    "        self.info = \"NONE\"\n",
    "        self.nextinfo = \"NONE\"\n",
    "        self.prevaction = \"NOOP\"\n",
    "        #Conversion of self.state to tuple for hashing purposes\n",
    "        #self.state = tuple([tuple(x) for x in self.state])\n",
    "        self.state_actions = []\n",
    "        self.highscore = 0\n",
    "        self.time = 0\n",
    "        self.linestates = []\n",
    "\n",
    "\n",
    "    def play(self):\n",
    "        self.steps_per_episode = []  \n",
    "        \n",
    "        for ep in range(self.episodes):\n",
    "            done = False\n",
    "            while not done:\n",
    "\n",
    "                action = self.chooseAction()\n",
    "                self.oops = False\n",
    "                self.state_actions.append((self.state, action))\n",
    "                try:\n",
    "                    previnfo = info[\"current_piece\"]\n",
    "                except:\n",
    "                    j = \"j\"\n",
    "\n",
    "                #unusedstate, reward, done, info = self.env.step(self.env.action_space.sample())\n",
    "                \n",
    "                print((MOVEMENT[action], list(self.env.ram[0x0040:0x0042])))\n",
    "                #time.sleep(1)\n",
    "                \n",
    "                unusedstate, reward, done, info = self.env.step(action)\n",
    "                \n",
    "                #print(tuple(self.env.ram[0x0040:0x0042]))\n",
    "                time.sleep(1)\n",
    "                \n",
    "                #print(self.env.ram[0x0045])\n",
    "                try:\n",
    "                    if previnfo[0] != info[\"current_piece\"][0]:\n",
    "                        #print(previnfo)\n",
    "                        #print(prevpos)\n",
    "                        #Time assuming no action: 960\n",
    "                        #Time assuming down: 49\n",
    "                        #print(self.time)\n",
    "                        self.oops = True\n",
    "                except:\n",
    "                    j = \"j\"\n",
    "                #print(info[\"current_piece\"])\n",
    "                #print(info[\"next_piece\"])\n",
    "                #print(self.env.ram[0x0042])\n",
    "                if self.env.ram[0x0048] != 1:\n",
    "                    print(self.time)\n",
    "                \n",
    "                self.env.render()\n",
    "                self.state = tuple([ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()), info[\"current_piece\"], info[\"next_piece\"], tuple(self.env.ram[0x0040:0x0042])])\n",
    "                self.info = info[\"current_piece\"]\n",
    "                self.nextinfo = info[\"next_piece\"]\n",
    "                \n",
    "                #if info[\"current_piece\"] == \"Tu\":\n",
    "                    #print(info[\"current_piece\"])\n",
    "                    #time.sleep(10)\n",
    "                \n",
    "                #if CollisionDetection(self.state[0], self.state[1], self.state[3]) == False:\n",
    "                    #print(self.state[1])\n",
    "                    #print(self.state[3])\n",
    "                    #time.sleep(10)\n",
    "                \n",
    "                self.highscore = info[\"score\"]\n",
    "                self.time += 1\n",
    "                self.linestates.append(info[\"board_height\"])\n",
    "\n",
    "            # end of game\n",
    "            #if ep % 10 == 0:\n",
    "            self.listofhighscores.append(self.highscore)\n",
    "            self.listofhighscorerates.append(self.highscore / self.time)\n",
    "            self.listofsafetyscores.append(sum(self.linestates) / self.time)\n",
    "            print(\"episode\", ep)\n",
    "            print(\"Highscore: \" + str(self.highscore))\n",
    "            print(\"Score rate: \" + str(self.highscore / self.time))\n",
    "            print(\"Safety score: \" + str(sum(self.linestates) / self.time))\n",
    "            self.steps_per_episode.append(len(self.state_actions))\n",
    "            #print(ColorBoardtoSimpleBoard(self.env.ram[0x0400:0x04C8].reshape((20, 10)).copy()))\n",
    "            self.reset()\n",
    "        self.env.close()\n",
    "if __name__ == \"__main__\":\n",
    "    N_EPISODES = 1\n",
    "    # comparison\n",
    "    agent = Agent(episodes=N_EPISODES, test=solved)\n",
    "    agent.play()\n",
    "\n",
    "    highscores = agent.listofhighscores\n",
    "    highscorerates = agent.listofhighscorerates\n",
    "    safetyscores = agent.listofsafetyscores\n",
    "\n",
    "    plt.figure(figsize=[10, 6])\n",
    "    plt.ylim(0, 50)\n",
    "    plt.plot(range(N_EPISODES), highscores, label=\"high score\")\n",
    "    plt.legend()\n",
    "        \n",
    "    plt.figure(figsize=[10, 6])\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.plot(range(N_EPISODES), highscorerates, label=\"score rate\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(figsize=[10, 6])\n",
    "    plt.ylim(4, 12)\n",
    "    plt.plot(range(N_EPISODES), safetyscores, label=\"safety score\")\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
